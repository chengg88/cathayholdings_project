{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import cv2\n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch import nn\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"archive\\Brain Tumor\\Brain Tumor\"\n",
    "df = pd.read_csv(\"archive\\Brain Tumor.csv\")\n",
    "df[\"Image\"] = df[\"Image\"].apply(lambda x: x+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, height, width, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)[[\"Class\"]]\n",
    "        self.img_name =  pd.read_csv(annotations_file)[[\"Image\"]].apply(lambda x: x+\".jpg\")\n",
    "        self.img_name = self.img_name\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.height = height  # Debug\n",
    "        self.width = width\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_name.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        # resize = transforms.Resize([self.width, self.height])  # Debug: resize img to let all images in same size.\n",
    "        # image = resize(image)\n",
    "        label = self.img_labels.iloc[idx, 0]  # Debug: 要修改成[idx, 0]才是取數值，不會把欄位名稱一起誤抓        \n",
    "        # print(\"label:\", label)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32]) 0\n",
      "3762\n"
     ]
    }
   ],
   "source": [
    "dataset = CustomImageDataset(annotations_file=\"archive\\Brain Tumor.csv\",\n",
    "                             img_dir=\"archive\\Brain Tumor\\Brain Tumor\", height = 32, width=32,\n",
    "                             transform = transforms.Compose([\n",
    "                                transforms.Resize((32,32)),  # 將圖片從原先大小28x28改成LeNet可以接受的輸入大小32x32\n",
    "                                transforms.ToTensor(),  # 轉換成tensor並且將像素範圍(range)從[0, 255]改到[0,1]\n",
    "                                transforms.Normalize(mean = (0.1307,), std = (0.3081,))]))\n",
    "\n",
    "# pick 1000th img data in dataset\n",
    "first_data = dataset[1000]\n",
    "features, labels = first_data\n",
    "print(features.shape, labels)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size, test_size = 0.1, 0.1  # train:val:test=0.8:0.1:0.1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64  # 每個batch有64張圖片\n",
    "num_classes = 2  # 圖片共分成10種類別\n",
    "learning_rate = 0.001  # 學習率\n",
    "num_epochs = 30  #　訓練總共要跑的回合數，一回合(epoch)即將所有訓練數據都掃過一遍\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Create data indices for train & validatin spilt\n",
    "# Set seed and shuffle, then spilt data to train, validation, test\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "val_spilt = int(np.floor(val_size * dataset_size))\n",
    "test_spilt = val_spilt + int(np.floor(test_size * dataset_size))\n",
    "\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "train_indices, val_indices, test_indices = indices[test_spilt:], indices[:val_spilt], indices[val_spilt:test_spilt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=val_sampler)\n",
    "test_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the convolutional neural network\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5(num_classes).to(device)\n",
    "cost = nn.CrossEntropyLoss()  # 交叉墒損失函數，適用多分類任務的損失函數\n",
    "#Setting the optimizer with the model parameters and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Adam優化器\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [48/48], Loss: 0.2751\n",
      "Epoch [2/30], Step [48/48], Loss: 0.0371\n",
      "Epoch [3/30], Step [48/48], Loss: 0.4480\n",
      "Epoch [4/30], Step [48/48], Loss: 0.2909\n",
      "Epoch [5/30], Step [48/48], Loss: 0.9025\n",
      "Epoch [6/30], Step [48/48], Loss: 0.0319\n",
      "Epoch [7/30], Step [48/48], Loss: 0.0054\n",
      "Epoch [8/30], Step [48/48], Loss: 0.0406\n",
      "Epoch [9/30], Step [48/48], Loss: 2.4273\n",
      "Epoch [10/30], Step [48/48], Loss: 0.0385\n",
      "Epoch [11/30], Step [48/48], Loss: 0.0381\n",
      "Epoch [12/30], Step [48/48], Loss: 1.2239\n",
      "Epoch [13/30], Step [48/48], Loss: 0.2187\n",
      "Epoch [14/30], Step [48/48], Loss: 0.1091\n",
      "Epoch [15/30], Step [48/48], Loss: 0.0088\n",
      "Epoch [16/30], Step [48/48], Loss: 0.0001\n",
      "Epoch [17/30], Step [48/48], Loss: 0.0064\n",
      "Epoch [18/30], Step [48/48], Loss: 0.0378\n",
      "Epoch [19/30], Step [48/48], Loss: 0.0004\n",
      "Epoch [20/30], Step [48/48], Loss: 0.2371\n",
      "Epoch [21/30], Step [48/48], Loss: 0.0083\n",
      "Epoch [22/30], Step [48/48], Loss: 0.0102\n",
      "Epoch [23/30], Step [48/48], Loss: 0.0108\n",
      "Epoch [24/30], Step [48/48], Loss: 0.0776\n",
      "Epoch [25/30], Step [48/48], Loss: 0.0367\n",
      "Epoch [26/30], Step [48/48], Loss: 0.5318\n",
      "Epoch [27/30], Step [48/48], Loss: 0.0007\n",
      "Epoch [28/30], Step [48/48], Loss: 0.0000\n",
      "Epoch [29/30], Step [48/48], Loss: 0.0401\n",
      "Epoch [30/30], Step [48/48], Loss: 2.1560\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):  # 總共進行共num_epochs個回合的訓練\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)  # 將tensor移動到GPU或CPU上訓練\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # 前向傳播(Forward pass)\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \t\n",
    "        # 反向傳播(Backward pass) and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \t\t\n",
    "        if (i+1) % 48 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.47872340425532 %\n"
     ]
    }
   ],
   "source": [
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)  # 總共預測的圖片張數\n",
    "        correct += (predicted == labels).sum().item()  # 統計預測正確的圖片張數\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))  # 模型在測試資料的預測準確率(accuracy)\n",
    "\t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             456\n",
      "       BatchNorm2d-2            [-1, 6, 28, 28]              12\n",
      "              ReLU-3            [-1, 6, 28, 28]               0\n",
      "         MaxPool2d-4            [-1, 6, 14, 14]               0\n",
      "            Conv2d-5           [-1, 16, 10, 10]           2,416\n",
      "       BatchNorm2d-6           [-1, 16, 10, 10]              32\n",
      "              ReLU-7           [-1, 16, 10, 10]               0\n",
      "         MaxPool2d-8             [-1, 16, 5, 5]               0\n",
      "            Linear-9                  [-1, 120]          48,120\n",
      "             ReLU-10                  [-1, 120]               0\n",
      "           Linear-11                   [-1, 84]          10,164\n",
      "             ReLU-12                   [-1, 84]               0\n",
      "           Linear-13                    [-1, 2]             170\n",
      "================================================================\n",
      "Total params: 61,370\n",
      "Trainable params: 61,370\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.16\n",
      "Params size (MB): 0.23\n",
      "Estimated Total Size (MB): 0.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
